{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8ccb68",
   "metadata": {},
   "source": [
    "# Interactive White Matter Segmentation\n",
    "\n",
    "In this notebook you'll have the opportunity to perform an interactive, anatomically based white matter segmentation right here in the browser, using your own data.  This will allow you to explore the anatomical connectivity instantiated in your tractogram to get a sense of the quality of your tractography data, what parts of the brain are connected to what (according to your tracrogram), and how well your volumetric atlas serves your needs.  \n",
    "\n",
    "## Initial setup\n",
    "Before we can do any of this though, we have to make sure this notebook is setup correctly and can access your data.\n",
    "\n",
    "### Using this notebook locally\n",
    "\n",
    "If you're using this notebook locally, one of the foremost things you should ensure is that your local python environment has the necessary packages installed.  Check the **requirements.txt** file in this repository to determine which packages are necessary.\n",
    "\n",
    "When running this notebook locally, you should be able to navigate to the appropriate folder(s) containing your data using the file chooser provided by the subsequent cells.\n",
    "\n",
    "### Jupyterlab / binder\n",
    "\n",
    "If you're using a [jupyterlab](https://jupyter.org/) [binder](https://mybinder.org/), there's an extra step to making your data avaialble to this interface.  In order to do this, you'll need to upload your data to this virtual environment.  NOTE: because this is a temporary virtual environment, any data that you upload here will not be preserved.  All the same, it is best to be careful about what data is uploaded.  To upload data to this [jupyterlab](https://jupyter.org/) environment Click the **file icon** in the **left hand menu**, then click the **underlined up arrow** to begin the upload selection.  This should be sufficient setup, as package managment is taken care of by these platforms.\n",
    "\n",
    "### Jupyter Notebook Classic / binder\n",
    "\n",
    "Alternatively, if you're using a classic jupyter-notebook [binder](https://mybinder.org/) (acheived by clicking **Launch Classic Notebook** under the **help menu**, and temporarily _reccomended_ until widget interfacing has been fixed in jupyterlab) click the **upload** button towards the upper right hand side of the interface and upload the files below, and then select this notebook (InteractiveWhiteMatterSegmentation.ipynb) and proceed normally.\n",
    "\n",
    "## Target data\n",
    "\n",
    "For this particular notebook to operate successfully you'll need to upload the following:\n",
    "\n",
    "- The desired volumetric brain segmentation that will be used to specify brain areas that you wish to view connectivity between (the atlas and the tractrogram should be aligned to one another / in the same space).\n",
    "- A whole-brain tractogram containing the candidate streamlines you wish to inspect/segment (the atlas and the tractrogram should be aligned to one another / in the same space).\n",
    "- A lookup table (csv or xls) indicating the human-interpretable identities of the labels in the volumetric brain atlas file.\n",
    "\n",
    "In the several of the following cells, you will be asked to select/specify your data targets.  Their location will depend on the method by which you are interfacing with this notebook (as described in the [Initial setup](#Initial setup) section.  As with any jupyter notebook, you will need to hit **run** for each cell in order to proceed.  For data upload blocks this will trigger the provision of a file-chooser interface.  For other code blocks, running the cell will result in the production of a visualization, table, or other graphical/interactive feature.\n",
    "\n",
    "## The Atlas\n",
    "\n",
    "### Selecting the atlas\n",
    "We'll begin by selecting the volumetric brain atlas that you would like to use to select your streamlines of interest.  Later on, you'll be selecting labels/regions from this atlas as a means of indicating that you would like to visualize streamlines that begin or end (tractography is agnostic with respect to directionality) in these areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183676ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#upload widget not working right now, just use path specification for current purposes\n",
    "#import ipywidgets as widgets\n",
    "#uploader = widgets.FileUpload()\n",
    "#uploader\n",
    "\n",
    "#set path to atlas\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "if 'fcAtlas' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcAtlas.selected_path==None:\n",
    "        print('Please select your input atlas file')\n",
    "        fcAtlas = FileChooser(os.getcwd())\n",
    "        display(fcAtlas)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcAtlas.default_path = fcAtlas.selected_path\n",
    "        fcAtlas.default_filename=fcAtlas.selected_filename\n",
    "        display(fcAtlas)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcAtlas' in locals()):\n",
    "    fcAtlas = FileChooser(os.getcwd())\n",
    "    print('Please select your input atlas file')\n",
    "    display(fcAtlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e6a6",
   "metadata": {},
   "source": [
    "## The reference anatomy\n",
    "\n",
    "In order to get a better look at what has been segmented (and because there is no reference anatomy in the above visualization) we can also convert these selected streamlines to a density map and plot them on a reference T1.  To do this we'll need to upload a reference T1 in the same fashion as our other data objects.\n",
    "\n",
    "**Note**: this will only be useful _if_ the T1 image is aligned to / in the same space as the tractography.\n",
    "\n",
    "(after selecting the file to upload, run the subsequent cell as well in order to create an interactive visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfe775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "if 'T1path' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if T1path.selected_path==None:\n",
    "        print('Please select your T1 file')\n",
    "        T1path = FileChooser(os.getcwd())\n",
    "        display(T1path)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        T1path.default_path = T1path.selected_path\n",
    "        T1path.default_filename=T1path.selected_filename\n",
    "        display(T1path)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('T1path' in locals()):\n",
    "    T1path = FileChooser(os.getcwd())\n",
    "    print('Please select your input T1 file')\n",
    "    display(T1path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f08c69",
   "metadata": {},
   "source": [
    "### Loading and inspecting the atlas\n",
    "\n",
    "Now that we have selected the atlas file, let's take a moment to inspect it.  Run the next cell, and then feel free to use the X, Y, and Z sliders to move about the atlas volume.  Although it is not possible from this visualization to interpret which labels are where, it is possible to get a sense of what the atlas's coverage is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a2bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conditionally plot the atlas if a file has been chosen.  If not, print warning.\n",
    "#this might be avoidable with a clever use of observe\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from dipy.tracking.utils import reduce_labels\n",
    "if not(fcAtlas.selected_path==None):\n",
    "    pathToAtlas=os.path.join(fcAtlas.selected_path,fcAtlas.selected_filename)\n",
    "    #load the nifti\n",
    "    import nibabel as nib\n",
    "    atlasImg = nib.load(pathToAtlas)\n",
    "    T1ToLoad=(os.path.join(T1path.selected_path,T1path.selected_filename))\n",
    "    t1img = nib.load(T1ToLoad)\n",
    "    from nilearn import plotting\n",
    "\n",
    "    print('relabeling atlas')\n",
    "    #zero index necessary because function returns tuple?\n",
    "    relabeledAtlasData=reduce_labels(atlasImg.get_fdata())[0]\n",
    "\n",
    "    #save to working directory; required as nifitWidget doesn't load from object apparently\n",
    "    renumberedAtlasNifti=nib.Nifti1Image(relabeledAtlasData, atlasImg.affine, atlasImg.header) \n",
    "    #save the object down\n",
    "    nib.save(renumberedAtlasNifti, 'relabeledAtlas.nii.gz')\n",
    "\n",
    "    #create a distinguishable colormap\n",
    "    import matplotlib.pyplot as plt\n",
    "    uniqueColors=plt.cm.get_cmap('hsv', np.max(renumberedAtlasNifti.get_fdata()))\n",
    "    \n",
    "    display(plotting.view_img(stat_map_img=renumberedAtlasNifti, bg_img=t1img,dim=2 ,opacity=.5, cut_coords=None,colorbar=True,cmap=uniqueColors, symmetric_cmap=False).resize(900,400))\n",
    "else:\n",
    "    print('No input atlas file selected.  Please return to previous cell, select an atlas file, and rerun this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc228726",
   "metadata": {},
   "source": [
    "## The lookup table\n",
    "\n",
    "### Selecting the lookup table\n",
    "\n",
    "Next we'll select the Lookup table for the atlas you have provided.  The Lookup table provides information about the correspondances of the numerical labels in the atlas file you just provided with the anatomical/conceptual entities they are supposed to designate (as described [here, in a broad manner](https://dannbullock.github.io/WiMSE/notebooks/How_to_interpret_a_volumetric_brain_segmentation.html) and [here, in the context of color lookup tables](https://www.slicer.org/wiki/Documentation/4.1/SlicerApplication/LookupTables).\n",
    "\n",
    "We will be using an interactive interface with a spreadsheet version of the lookup table in order to select which labels will be required endpoints for our streamlines of interest.  Technically you do not need to provide an Lookup table, as this notebook will peice together a spreadsheet label-selection interface in one is not found, however such an interface will have no terminology-based labeling information and will thus be fairly difficult to interpret or work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a361c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set path to atlas\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "if 'fcLUT' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcLUT.selected_path==None:\n",
    "        print('Please select your input Lookup table file')\n",
    "        fcLUT = FileChooser(os.getcwd())\n",
    "        display(fcLUT)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcLUT.default_path = fcLUT.selected_path\n",
    "        fcLUT.default_filename=fcLUT.selected_filename\n",
    "        display(fcLUT)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcLUT' in locals()):\n",
    "    fcLUT = FileChooser(os.getcwd())\n",
    "    print('Please select your input Lookup table file')\n",
    "    display(fcLUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67696bb",
   "metadata": {},
   "source": [
    "### Inspecting and interacting with the lookup table\n",
    "\n",
    "Lets take a quick look at the LUT that has been provided (or that will be built) using [qgrid](https://github.com/quantopian/qgrid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fe4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conditionally plot the atlas if a file has been chosen.  If not, build a table from the information in the passed atlas.\n",
    "#this might be avoidable with a clever use of observe\n",
    "import pandas as pd\n",
    "if not(fcLUT.selected_path==None):\n",
    "    LUTpath=os.path.join(fcLUT.selected_path,fcLUT.selected_filename)\n",
    "    if fcLUT.selected_filename[-4:]=='.csv':\n",
    "        LUT=pd.read_csv(LUTpath)\n",
    "    elif (fcLUT.selected_filename[-4:]=='.xls',fcLUT.selected_filename[-5:]=='.xlsx'):\n",
    "        LUT=pd.read_excel(LUTpath)\n",
    "else:\n",
    "    #build it from the input data\n",
    "    import numpy as np\n",
    "    inferredLUTIdentities={'origLabels': np.unique(atlasImg.get_fdata()).astype(int),'newLabels':np.unique(renumberedAtlasNifti.get_fdata()).astype(int)}\n",
    "    LUT=pd.DataFrame(data=inferredLUTIdentities)  \n",
    "\n",
    "#one way or the other the LUT should now be available\n",
    "import qgrid\n",
    "qgrid_firstLUT_widget= qgrid.show_grid(LUT,show_toolbar=True)\n",
    "qgrid_firstLUT_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd100c",
   "metadata": {},
   "source": [
    "## The tractogram\n",
    "\n",
    "### Selecting the tractogram \n",
    "\n",
    "Next, let's select the tractogram file.  Due to the [RAM limitations of binder](https://mybinder.readthedocs.io/en/latest/about/about.html#how-much-memory-am-i-given-when-using-binder), if you are using binder or a similar service, it is **strongly** recomend that you limit the size of the uploaded tractogram to less than 1.25 GB.  Otherwise, tractogram limitations are associated with your local hardware (in particular RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565b659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "if 'fcTractogram' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcTractogram.selected_path==None:\n",
    "        print('Please select your input tractogram file')\n",
    "        fcTractogram = FileChooser(os.getcwd())\n",
    "        display(fcTractogram)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcTractogram.default_path = fcTractogram.selected_path\n",
    "        fcTractogram.default_filename=fcTractogram.selected_filename\n",
    "        display(fcTractogram)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcTractogram' in locals()):\n",
    "    fcTractogram = FileChooser(os.getcwd())\n",
    "    print('Please select your input tractogram file')\n",
    "    display(fcTractogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933685f",
   "metadata": {},
   "source": [
    "## Selecting your rois\n",
    "\n",
    "Next, we'll use the refernce T1 image to help us place a spherical ROI, which we will then use to segment streamlines from our tractogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code ensures that we can navigate the WiMSE repo across multiple systems\n",
    "import subprocess\n",
    "import os\n",
    "#get top directory path of the current git repository, under the presumption that \n",
    "#the notebook was launched from within the repo directory\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "\n",
    "#establish path to the wma_tools repo\n",
    "wma_toolsDirPath=os.path.join(gitRepoPath,'wma_pyTools')   \n",
    "\n",
    "#change to the wma_tools path, load the function set, then change back to the top directory\n",
    "os.chdir(wma_toolsDirPath)\n",
    "import WMA_pyFuncs\n",
    "os.chdir(gitRepoPath)\n",
    "\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import numpy as np\n",
    "segmentationQueueDF=pd.DataFrame(columns=['ROI_type','centerPoint','dimension or radius','include'])\n",
    "#we'll go ahead and populate the first record with a 5 mm sphere in the middle of the volume\n",
    "convertedBoundCoords=WMA_pyFuncs.subjectSpaceMaskBoundaryCoords(t1img)\n",
    "#this is the example query\n",
    "exampleQueryRow=['sphere',np.mean(convertedBoundCoords,axis=0),5,True]\n",
    "#convert it to a series\n",
    "querySeries = pd.Series(exampleQueryRow, index = segmentationQueueDF.columns)\n",
    "#append it\n",
    "segmentationQueueDF = segmentationQueueDF.append(querySeries, ignore_index=True)\n",
    "#render it into an interactive widget\n",
    "qgrid_segmentationQueue_widget= qgrid.show_grid(segmentationQueueDF,show_toolbar=True)\n",
    "qgrid_segmentationQueue_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import util\n",
    "\n",
    "roisNifti =[]\n",
    "include = []\n",
    "operations= []\n",
    "#get the resultant dataframe\n",
    "from dipy.tracking.utils import reduce_rois\n",
    "segmentationQueueDF=qgrid_segmentationQueue_widget.get_changed_df()\n",
    "\n",
    "    # generate some number of spheres to use in a test segmentation\n",
    "for iRois in list(range(len(segmentationQueueDF.index))):\n",
    "    #if it requests a sphere, create a sphere\n",
    "    if segmentationQueueDF.at[iRois,'ROI_type'].lower()=='sphere':\n",
    "        # obtain that data array as bool\n",
    "        currentROI=WMA_pyFuncs.createSphere(segmentationQueueDF.at[iRois,'dimension or radius'], segmentationQueueDF.at[iRois,'centerPoint'], t1img)\n",
    "    elif segmentationQueueDF.at[iRois,'ROI_type'].lower()=='plane':\n",
    "        # add that and a True to the list vector for each\n",
    "        currentROI=WMA_pyFuncs.makePlanarROI(t1img, float(segmentationQueueDF.at[iRois,'centerPoint']), segmentationQueueDF.at[iRois,'dimension or radius'])\n",
    "    else:\n",
    "        raise Exception(\"Input ROI type specification not understood.\")\n",
    "        \n",
    "    #in either case\n",
    "    roisNifti.append(currentROI)\n",
    "    #just seting this to any, can make this an option later\n",
    "    operations.append('any')\n",
    "    # convert include vector robustly\n",
    "    include.append(bool(util.strtobool(str(segmentationQueueDF.at[iRois,'include']))))\n",
    "    \n",
    "#obtain the data from each roi\n",
    "roisData=[iROI.get_fdata().astype(bool) for iROI in roisNifti]\n",
    "#condense the include and exclude ROIS\n",
    "include_roi, exclude_roi=reduce_rois(roisData, include)\n",
    "#create blank data object to serve as the merge,really only for visualization purposes\n",
    "roisMergeData=np.zeros(include_roi.shape, dtype=int)\n",
    "#set the entries to their respective values\n",
    "roisMergeData[include_roi]=1\n",
    "roisMergeData[exclude_roi]=-1\n",
    "mergedRoisNifti=nib.Nifti1Image(roisMergeData, t1img.affine, t1img.header) \n",
    "#plot these, for inspection\n",
    "display(plotting.view_img(stat_map_img=mergedRoisNifti, bg_img=t1img,dim=2 ,opacity=.5, cut_coords=None,colorbar=True,cmap='jet').resize(900,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6613e",
   "metadata": {},
   "source": [
    "## The segmentation\n",
    "\n",
    "### Performing the segmentation\n",
    "\n",
    "Now that we've entered the rois and visualized them, we can perform the segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da262e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load up the tractogram if possible\n",
    "if not(fcTractogram.selected_path==None):   \n",
    "    tractogramPath=(os.path.join(fcTractogram.selected_path,fcTractogram.selected_filename))\n",
    "    #do a check to see if the selected input file type is supported\n",
    "    if not(nib.streamlines.is_supported(tractogramPath)):\n",
    "        raise ValueError(\"Input tractogram file type not supported\")\n",
    "    else:\n",
    "        streamsObjIN=nib.streamlines.load(tractogramPath)\n",
    "\n",
    "def extractSubTractogram(sourceTractogram,indexes):\n",
    "    #import relevant package\n",
    "    import nibabel as nib\n",
    "    #extract the desired streamlines into a new streamline object\n",
    "    streamlines = sourceTractogram.streamlines[indexes]\n",
    "    #establish tractogram object\n",
    "    out_tractogram = nib.streamlines.tractogram.Tractogram(streamlines)\n",
    "    return out_tractogram\n",
    "\n",
    "#interactive plotting via niwidgets?  \n",
    "#widget within a widget doesn't seem to work\n",
    "def plotSegmentedStreamsWidget(subTractogram):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    sw = StreamlineWidget(streamlines=subTractogram)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                  'label': {'color': 'white'},\n",
    "                  'ticklabel': {'color': 'white'},\n",
    "                  'visible': True},\n",
    "         'background-color': 'black',\n",
    "         'box': {'visible': True}}\n",
    "    #plot it\n",
    "    %matplotlib inline\n",
    "    display(sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=0))\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#use the criteria application function to find the relevant streamlines\n",
    "streamBool=WMA_pyFuncs.segmentTractMultiROI(streamsObjIN.streamlines, roisNifti, include , operations)\n",
    "    \n",
    "streamsToPlot=extractSubTractogram(streamsObjIN,np.where(streamBool)[0])\n",
    "  \n",
    "display(plotSegmentedStreamsWidget(streamsToPlot.streamlines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a92e1b",
   "metadata": {},
   "source": [
    "### Examining streamline density relative to anatomy\n",
    "\n",
    "In order to obtain a more informed understanding of the selected streamlines and their location in the brain, we can plot their density overlain on the T1 anatomy as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034d06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load selected t1 image\n",
    "import nibabel as nib\n",
    "import os\n",
    "#load the T1\n",
    "T1ToLoad=(os.path.join(T1path.selected_path,T1path.selected_filename))\n",
    "t1img = nib.load(T1ToLoad)\n",
    "\n",
    "#use dipy to create the density mask\n",
    "from dipy.tracking import utils\n",
    "densityMap=utils.density_map(streamsToPlot.streamlines, t1img.affine, t1img.shape)\n",
    "densityNifti=nib.nifti1.Nifti1Image(densityMap,t1img.affine, t1img.header)\n",
    "\n",
    "from nilearn import plotting\n",
    "plotting.view_img(stat_map_img=densityNifti, bg_img=t1img, cut_coords=None,colorbar=True,vmin=0,vmax=np.max(densityNifti.get_fdata()),cmap='viridis', symmetric_cmap=False).resize(900,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc113d",
   "metadata": {},
   "source": [
    "### Where are these streamlines terminating\n",
    "\n",
    "We may also be curious about what areas from the input atlas these streamlines are terminating in.  To this end we can perform a quick atlas based segmentation and plot the quantative results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0cc2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "#segment tractome into connectivity matrix from parcellation\n",
    "M, grouping=utils.connectivity_matrix(streamsToPlot.streamlines, atlasImg.affine, label_volume=renumberedAtlasNifti.get_fdata().astype(int),\n",
    "                            return_mapping=True,\n",
    "                            mapping_as_streamlines=False)\n",
    "# if the length of the provided LUT exceeds the number of unique entries, then the indexes of the table cannot be relied\n",
    "#upon to provide us with the correspondance to the relabeled atlas.  If this is the case, try and implement a workaround.\n",
    "if len(LUT)>len(np.unique(relabeledAtlasData)):\n",
    "    #infer which column contains the original identities\n",
    "    #presumably, this would be the LUT column with the largest number of matching labels with the original atlas.\n",
    "    matchingLabelsCount=[len(list(set(LUT[iColumns]).intersection(set(np.unique(atlasImg.get_fdata()).astype(int))))) for iColumns in LUT.columns.to_list()]\n",
    "    #there's an edge case here relabeled atlas == the original atlas AND the provided LUT was larger (what would the extra entries be?)\n",
    "    #worry about that later\n",
    "    columnBestGuess=LUT.columns.to_list()[matchingLabelsCount.index(np.max(matchingLabelsCount))]\n",
    "    #now that we have the guess, get the corresponding row entries, and reset the index.\n",
    "    #This should make the index match the renumbered label values.\n",
    "    LUTinterface=LUT[LUT[columnBestGuess].isin(np.unique(atlasImg.get_fdata()).astype(int)).values].reset_index(drop=True)\n",
    "\n",
    "#in order to provide some intuitons about where to look, add a column indicating the number of endpoints in that label.\n",
    "#this could probably just be an interative sum across row operation for the connectivty matrix.\n",
    "connectionLocations=[]\n",
    "#create a list of lists of all if the keys featuring this index\n",
    "for iIndexes in LUT.index.to_list():\n",
    "    connectionLocations.append( [iIndexes in sublist for sublist in list(grouping.keys())])\n",
    "    \n",
    "#get the dictionary keys in a list\n",
    "keyTargets=list(grouping.keys())\n",
    "#create a blank output vector\n",
    "streamCounts=np.zeros(len(LUTinterface),dtype=int)\n",
    "#iterate across all labels\n",
    "for iLabels in LUTinterface.index.to_list():\n",
    "    #find the dictionary keys which feature this connection\n",
    "    currentKeylocations=[i for i, x in enumerate(connectionLocations[iLabels]) if x]\n",
    "    #create a zero holder for a streamline accumulator/counter\n",
    "    currentStreamTotal=0\n",
    "    #iterate across the found connections for this key\n",
    "    for iCurrentConnections in currentKeylocations:\n",
    "        #add the number of streamlines to the streamline total\n",
    "        currentStreamTotal=currentStreamTotal+len(grouping[keyTargets[iCurrentConnections]])\n",
    "    #set the value\n",
    "    streamCounts[iLabels]=currentStreamTotal\n",
    "if not(\"endpointCount\" in LUTinterface.columns):\n",
    "    LUTinterface.insert(2, \"endpointCount\",streamCounts, True) \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# subset the labels to plot to only those that have streamlines\n",
    "subsetDFtoPlot=LUTinterface[LUTinterface['endpointCount']>0]\n",
    "# dynamically set plot dimensions\n",
    "plotDim1=len(subsetDFtoPlot)*.3\n",
    "plt.figure(figsize=(5,plotDim1))\n",
    "\n",
    "#arbitrarily set for specific atlas for now, come back and make adaptive later\n",
    "yColumn='Full_Name'\n",
    "xColumn='endpointCount'\n",
    "ax = sns.barplot(y=yColumn, x=xColumn, data=subsetDFtoPlot)\n",
    "#set logscale\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set(title=\"Streamline connections found in current selection\", xlabel='log scale streamline count', ylabel='atlas label')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
