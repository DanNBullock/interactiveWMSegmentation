{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8ccb68",
   "metadata": {},
   "source": [
    "# Interactive White Matter Segmentation\n",
    "\n",
    "In this notebook you'll have the opportunity to perform an interactive, anatomically based white matter segmentation right here in the browser, using your own data.  This will allow you to explore the anatomical connectivity instantiated in your tractogram to get a sense of the quality of your tractography data, what parts of the brain are connected to what (according to your tracrogram), and how well your volumetric atlas serves your needs.  \n",
    "\n",
    "## Initial setup\n",
    "Before we can do any of this though, we have to make sure this notebook is setup correctly and can access your data.\n",
    "\n",
    "### Using this notebook locally\n",
    "\n",
    "If you're using this notebook locally, one of the foremost things you should ensure is that your local python environment has the necessary packages installed.  Check the **requirements.txt** file in this repository to determine which packages are necessary.\n",
    "\n",
    "When running this notebook locally, you should be able to navigate to the appropriate folder(s) containing your data using the file chooser provided by the subsequent cells.\n",
    "\n",
    "### Jupyterlab / binder\n",
    "\n",
    "If you're using a [jupyterlab](https://jupyter.org/) [binder](https://mybinder.org/), there's an extra step to making your data avaialble to this interface.  In order to do this, you'll need to upload your data to this virtual environment.  NOTE: because this is a temporary virtual environment, any data that you upload here will not be preserved.  All the same, it is best to be careful about what data is uploaded.  To upload data to this [jupyterlab](https://jupyter.org/) environment Click the **file icon** in the **left hand menu**, then click the **underlined up arrow** to begin the upload selection.  This should be sufficient setup, as package managment is taken care of by these platforms.\n",
    "\n",
    "### Jupyter Notebook Classic / binder\n",
    "\n",
    "Alternatively, if you're using a classic jupyter-notebook [binder](https://mybinder.org/) (acheived by clicking **Launch Classic Notebook** under the **help menu**, and temporarily _reccomended_ until widget interfacing has been fixed in jupyterlab) click the **upload** button towards the upper right hand side of the interface and upload the files below, and then select this notebook (InteractiveWhiteMatterSegmentation.ipynb) and proceed normally.\n",
    "\n",
    "## Target data\n",
    "\n",
    "For this particular notebook to operate successfully you'll need to upload the following:\n",
    "\n",
    "- The desired volumetric brain segmentation that will be used to specify brain areas that you wish to view connectivity between (the atlas and the tractrogram should be aligned to one another / in the same space).\n",
    "- A whole-brain tractogram containing the candidate streamlines you wish to inspect/segment (the atlas and the tractrogram should be aligned to one another / in the same space).\n",
    "- A lookup table (csv or xls) indicating the human-interpretable identities of the labels in the volumetric brain atlas file.\n",
    "\n",
    "In the several of the following cells, you will be asked to select/specify your data targets.  Their location will depend on the method by which you are interfacing with this notebook (as described in the [Initial setup](#Initial setup) section.  As with any jupyter notebook, you will need to hit **run** for each cell in order to proceed.  For data upload blocks this will trigger the provision of a file-chooser interface.  For other code blocks, running the cell will result in the production of a visualization, table, or other graphical/interactive feature.\n",
    "\n",
    "## The Atlas\n",
    "\n",
    "### Selecting the atlas\n",
    "We'll begin by selecting the volumetric brain atlas that you would like to use to select your streamlines of interest.  Later on, you'll be selecting labels/regions from this atlas as a means of indicating that you would like to visualize streamlines that begin or end (tractography is agnostic with respect to directionality) in these areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183676ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload widget not working right now, just use path specification for current purposes\n",
    "#import ipywidgets as widgets\n",
    "#uploader = widgets.FileUpload()\n",
    "#uploader\n",
    "\n",
    "#set path to atlas\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "if 'fcAtlas' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcAtlas.selected_path==None:\n",
    "        print('Please select your input atlas file')\n",
    "        fcAtlas = FileChooser(os.getcwd())\n",
    "        display(fcAtlas)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcAtlas.default_path = fcAtlas.selected_path\n",
    "        fcAtlas.default_filename=fcAtlas.selected_filename\n",
    "    \n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcAtlas' in locals()):\n",
    "    fcAtlas = FileChooser(os.getcwd())\n",
    "    print('Please select your input atlas file')\n",
    "    display(fcAtlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e6a6",
   "metadata": {},
   "source": [
    "## The reference anatomy\n",
    "\n",
    "In order to get a better look at what has been segmented (and because there is no reference anatomy in the above visualization) we can also convert these selected streamlines to a density map and plot them on a reference T1.  To do this we'll need to upload a reference T1 in the same fashion as our other data objects.\n",
    "\n",
    "**Note** this will only be useful **if** the T1 image is aligned to / in the same space as the tractography.\n",
    "\n",
    "(after selecting the file to upload, run the subsequent cell as well in order to create an interactive visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfe775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "if 'T1path' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if T1path.selected_path==None:\n",
    "        print('Please select your T1 file')\n",
    "        T1path = FileChooser(os.getcwd())\n",
    "        display(T1path)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        T1path.default_path = T1path.selected_path\n",
    "        T1path.default_filename=T1path.selected_filename\n",
    "        display(T1path)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('T1path' in locals()):\n",
    "    T1path = FileChooser(os.getcwd())\n",
    "    print('Please select your input T1 file')\n",
    "    display(T1path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f08c69",
   "metadata": {},
   "source": [
    "### Loading and inspecting the atlas\n",
    "\n",
    "Now that we have selected the atlas file, let's take a moment to inspect it.  Run both of the next **two** cells, and then feel free to use the X, Y, and Z sliders to move about the atlas volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditionally plot the atlas if a file has been chosen.  If not, print warning.\n",
    "#this might be avoidable with a clever use of observe\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "if not(fcAtlas.selected_path==None):\n",
    "    pathToAtlas=os.path.join(fcAtlas.selected_path,fcAtlas.selected_filename)\n",
    "    #load the nifti\n",
    "    import nibabel as nib\n",
    "    atlasImg = nib.load(pathToAtlas)\n",
    "    T1ToLoad=(os.path.join(T1path.selected_path,T1path.selected_filename))\n",
    "    t1img = nib.load(T1ToLoad)\n",
    "    from nilearn import plotting\n",
    "    #doesn't seem to work here, or anywhere that's in a loop/statement of some sort\n",
    "    plotting.view_img(stat_map_img=renumberedAtlasNifti, bg_img=t1img,dim=2 ,opacity=.5, cut_coords=None,colorbar=True,cmap='prism', symmetric_cmap=False).resize(900,400)\n",
    "\n",
    "    \n",
    "    #now relabel it; maybe not necessary with monkey atlases, we'll see\n",
    "\n",
    "    #in order to have visually distinguishable areas we have to renumber the labels in the data object\n",
    "    #this is because niwidgets scales the color map via the min and max values of the labeling scheme,\n",
    "    #rather than by unique values\n",
    "    #this takes a while to perform, so if it already exists, check, load it, and don't do it again.\n",
    "    if os.path.isfile('relabeledAtlas.nii.gz'):\n",
    "        renumberedAtlasNifti = nib.load('relabeledAtlas.nii.gz')\n",
    "        relabeledAtlasData=copy.deepcopy(renumberedAtlasNifti)\n",
    "    else:\n",
    "        #need to make a deep copy, otherwise the relabeling process relabels the origional\n",
    "        relabeledAtlasData=copy.deepcopy(atlasImg.get_fdata())\n",
    "\n",
    "        #get the unique entries\n",
    "        \n",
    "        uniqueAtlasEntries=np.unique(relabeledAtlasData).astype(int)\n",
    "\n",
    "        #iterate across unique label entries\n",
    "        for iLabels in range(len(uniqueAtlasEntries)):\n",
    "            #replace the current uniqueAtlasEntries value with the iLabels value\n",
    "            #constitutes a simple renumbering schema\n",
    "            relabeledAtlasData[relabeledAtlasData==uniqueAtlasEntries[iLabels]]=iLabels\n",
    "\n",
    "        #save to working directory; required as nifitWidget doesn't load from object apparently\n",
    "        renumberedAtlasNifti=nib.Nifti1Image(relabeledAtlasData, atlasImg.affine, atlasImg.header)  \n",
    "        #save the object down\n",
    "        nib.save(renumberedAtlasNifti, 'relabeledAtlas.nii.gz')\n",
    "\n",
    "\n",
    "    #plotting.view_img(t1img,cut_coords=None,colorbar=True,cmap='prism', symmetric_cmap=False).resize(900,400)\n",
    "    #from niwidgets import NiftiWidget\n",
    "    #atlas_widget = NiftiWidget('relabeledAtlas.nii.gz')\n",
    "    #atlas_widget.nifti_plotter(colormap='nipy_spectral')\n",
    "else:\n",
    "    print('No input atlas file selected.  Please return to previous cell, select an atlas file, and rerun this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a8dd3-e23a-40a2-8ed0-ae9e5f880fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#because nilearn.plotting.view_image is cantankerous\n",
    "plotting.view_img(stat_map_img=renumberedAtlasNifti, bg_img=t1img,dim=2 ,opacity=.5, cut_coords=None,colorbar=True,cmap='prism', symmetric_cmap=False).resize(900,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc228726",
   "metadata": {},
   "source": [
    "## The lookup table\n",
    "\n",
    "### Selecting the lookup table\n",
    "\n",
    "Next we'll select the Lookup table for the atlas you have provided.  The Lookup table provides information about the correspondances of the numerical labels in the atlas file you just provided with the anatomical/conceptual entities they are supposed to designate (as described [here, in a broad manner](https://dannbullock.github.io/WiMSE/notebooks/How_to_interpret_a_volumetric_brain_segmentation.html) and [here, in the context of color lookup tables](https://www.slicer.org/wiki/Documentation/4.1/SlicerApplication/LookupTables).\n",
    "\n",
    "We will be using an interactive interface with a spreadsheet version of the lookup table in order to select which labels will be required endpoints for our streamlines of interest.  Technically you do not need to provide an Lookup table, as this notebook will peice together a spreadsheet label-selection interface in one is not found, however such an interface will have no terminology-based labeling information and will thus be fairly difficult to interpret or work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a361c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to atlas\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "if 'fcLUT' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcLUT.selected_path==None:\n",
    "        print('Please select your input Lookup table file')\n",
    "        fcLUT = FileChooser(os.getcwd())\n",
    "        display(fcLUT)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcLUT.default_path = fcLUT.selected_path\n",
    "        fcLUT.default_filename=fcLUT.selected_filename\n",
    "        display(fcLUT)\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcLUT' in locals()):\n",
    "    fcLUT = FileChooser(os.getcwd())\n",
    "    print('Please select your input Lookup table file')\n",
    "    display(fcLUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67696bb",
   "metadata": {},
   "source": [
    "### Inspecting and interacting with the lookup table\n",
    "\n",
    "Lets take a quick look at the LUT that has been provided (or that will be built) using [qgrid](https://github.com/quantopian/qgrid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fe4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditionally plot the atlas if a file has been chosen.  If not, build a table from the information in the passed atlas.\n",
    "#this might be avoidable with a clever use of observe\n",
    "import pandas as pd\n",
    "if not(fcLUT.selected_path==None):\n",
    "    LUTpath=os.path.join(fcLUT.selected_path,fcLUT.selected_filename)\n",
    "    if fcLUT.selected_filename[-4:]=='.csv':\n",
    "        LUT=pd.read_csv(LUTpath)\n",
    "    elif (fcLUT.selected_filename[-4:]=='.xls',fcLUT.selected_filename[-5:]=='.xlsx'):\n",
    "        LUT=pd.read_excel(LUTpath)\n",
    "else:\n",
    "    #build it from the input data\n",
    "    import numpy as np\n",
    "    inferredLUTIdentities={'origLabels': np.unique(atlasImg.get_fdata()).astype(int),'newLabels':np.unique(renumberedAtlasNifti.get_fdata()).astype(int)}\n",
    "    LUT=pd.DataFrame(data=inferredLUTIdentities)  \n",
    "\n",
    "#one way or the other the LUT should now be available\n",
    "import qgrid\n",
    "qgrid_firstLUT_widget= qgrid.show_grid(LUT,show_toolbar=True)\n",
    "qgrid_firstLUT_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd100c",
   "metadata": {},
   "source": [
    "## The tractogram\n",
    "\n",
    "### Selecting the tractogram \n",
    "\n",
    "Next, let's select the tractogram file.  Due to the [RAM limitations of binder](https://mybinder.readthedocs.io/en/latest/about/about.html#how-much-memory-am-i-given-when-using-binder), if you are using binder or a similar service, it is **strongly** recomend that you limit the size of the uploaded tractogram to less than 1.25 GB.  Otherwise, tractogram limitations are associated with your local hardware (in particular RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a FileChooser widget\n",
    "# if a file has already been selected, do not revert to no file selected\n",
    "if 'fcTractogram' in locals():\n",
    "    #however, if the selected file path is None, do rectify that\n",
    "    if fcTractogram.selected_path==None:\n",
    "        print('Please select your input tractogram file')\n",
    "        fcTractogram = FileChooser(os.getcwd())\n",
    "        display(fcTractogram)\n",
    "    else:\n",
    "        # just redisplay what you already have\n",
    "        fcTractogram.default_path = fcTractogram.selected_path\n",
    "        fcTractogram.default_filename=fcTractogram.selected_filename\n",
    "#if it doesn't exist at all (not sure how that would happen) also be sure to rectify that\n",
    "elif not('fcTractogram' in locals()):\n",
    "    fcTractogram = FileChooser(os.getcwd())\n",
    "    print('Please select your input tractogram file')\n",
    "    display(fcTractogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933685f",
   "metadata": {},
   "source": [
    "## Visualizing and interacting with the tractogram\n",
    "\n",
    "Now that you have selected your tractogram, lets interactively view it.\n",
    "\n",
    "**NOTE**: due to [an ipyvolume idiosyncracy](https://github.com/maartenbreddels/ipyvolume/issues/206) the following visualization widget will begin in an extremely zoomed out state.  Use your middle mouse button (or mouse scroll inteface) to zoom in on the tracrogram visualization)\n",
    "\n",
    "**Warning**:  If you have more than 100,000 streamlines in your input tractogram, it is _highly_ recommended that you skip the next cell and move on to the dipy-based segmentation as this next visualization would be incredibly demanding of available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3823dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "#conditionally plot the tractogram if a file has been chosen.  If not, print warning.\n",
    "#this might be avoidable with a clever use of observe\n",
    "def plotParcellationConnectionWidget(tractogramToPlot):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    tractogramToPlot\n",
    "    sw = StreamlineWidget(streamlines=tractogramToPlot.streamlines)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                'label': {'color': 'white'},\n",
    "                'ticklabel': {'color': 'white'},\n",
    "                'visible': False},\n",
    "                'background-color': 'black',\n",
    "                'box': {'visible': False}}\n",
    "        \n",
    "    #plot it\n",
    "    #set a viable threshold for how many streamlines to default to plotting\n",
    "    #likely dependant on available resources and such\n",
    "    streamThresh=25000\n",
    "    if len(tractogramToPlot.streamlines)<=streamThresh:\n",
    "        defaultPercentile=0\n",
    "        print('Plotting tractogram for all ' + str(len(tractogramToPlot.streamlines)) + ' streamlines.') \n",
    "    else:\n",
    "        defaultPercentile=1-(len(tractogramToPlot.streamlines)/streamThresh)\n",
    "        print('Plotting tractogram for ' + str(((1-defaultPercentile)*streamThresh)) +' of ' + str(len(streamsObjIN.streamlines)) + ' streamlines.')\n",
    "      \n",
    "    sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=defaultPercentile)\n",
    "\n",
    "if not(fcTractogram.selected_path==None):   \n",
    "    tractogramPath=(os.path.join(fcTractogram.selected_path,fcTractogram.selected_filename))\n",
    "    #compute size and throw warning or error if file size too \n",
    "    tractogramGBSize=os.path.getsize(tractogramPath)/(1024*1024*1024)\n",
    "    if 2>tractogramGBSize>1.25:\n",
    "        import warnings\n",
    "        warnings.warn(\"Input size of tractogram (\"+str(tractogramGBSize)+\"GB) exceeds recomended value\")\n",
    "    elif tractogramGBSize>2: \n",
    "        raise ValueError(\"Input size of tractogram (\"+str(tractogramGBSize)+\"GB) exceeds maximum RAM allocation\")\n",
    "\n",
    "    #do a check to see if the selected input file type is supported\n",
    "    if not(nib.streamlines.is_supported(tractogramPath)):\n",
    "        raise ValueError(\"Input tractogram file type not supported\")\n",
    "    else:\n",
    "        streamsObjIN=nib.streamlines.load(tractogramPath)\n",
    "\n",
    "    \n",
    "    display(plotParcellationConnectionWidget(streamsObjIN))\n",
    "else:\n",
    "    print('No input tractogram file selected.  Please return to previous cell, select a tractogram file, and rerun this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc113d",
   "metadata": {},
   "source": [
    "## The segmentation\n",
    "\n",
    "### An initial segmentation of the tractogram\n",
    "\n",
    "Now we'll use [dipy](https://dipy.org/) to perform a _full segmentation_ (as demonstrated and described [here](https://dannbullock.github.io/WiMSE/notebooks/A_first_segmentation.html)) and then, using the aforementioned looktable interface, select those labels that we wish to require our streamlines of interest to have endpoints in.  The goal of this is two-fold.  First, the resultant heatmap plot gives us an impression (however abstract) of the overall pattern of connectivity instantiated in our input tractome.  Second, the pre-application of this segmentation makes the later selection of streamlines _much_ simpler.\n",
    "\n",
    "**NOTE**: This process may take a non-trivial amount of time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400297b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "if not(fcTractogram.selected_path==None):   \n",
    "    tractogramPath=(os.path.join(fcTractogram.selected_path,fcTractogram.selected_filename))\n",
    "\n",
    "    #do a check to see if the selected input file type is supported\n",
    "    if not(nib.streamlines.is_supported(tractogramPath)):\n",
    "        raise ValueError(\"Input tractogram file type not supported\")\n",
    "    else:\n",
    "        streamsObjIN=nib.streamlines.load(tractogramPath)\n",
    "else:\n",
    "    print('No input tractogram file selected.  Please return to tractogram input cell, select an tractogram file, and rerun this cell.')\n",
    "\n",
    "from dipy.tracking import utils\n",
    "#segment tractome into connectivity matrix from parcellation\n",
    "M, grouping=utils.connectivity_matrix(streamsObjIN.tractogram.streamlines, atlasImg.affine, label_volume=renumberedAtlasNifti.get_fdata().astype(int),\n",
    "                            return_mapping=True,\n",
    "                            mapping_as_streamlines=False)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print('Connectivity profile for ' + str(len(streamsObjIN.tractogram.streamlines)) + ' streamlines.')\n",
    "sns.heatmap(np.log1p(M))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cb0e7",
   "metadata": {},
   "source": [
    "### Selecting anatomical regions of interest\n",
    "\n",
    "Now, lets use qgrid once more, but this time, you (the user) will be tasked with modifying the table in accordance with your segmentation goals.  In the table below, use the information in the column associated with anatomical terminology (if available) to select the labels that you wish to use as endpoint criteria for selecting streamlines.  Feel free to use the search functionality of the table by clicking the symbol beside a column's name.\n",
    "\n",
    "To add a label to a either criteria \"region1\" or criteria \"region2\" place a value of **1** (as in the form of a **boolean vector** in the corresponding column.  The labels will be combined into \"region1\" and \"region2\" in accordance with this input, and (in the next cell) the ccoresponding streamlines will be displayed.\n",
    "\n",
    "**Because it can be easy to reset the jupyter cell type to \"Markdown\" when making this selection, the next code cell's metadata has been set to prevent modifying the code, you may change this metadata setting if you wish.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# if the length of the provided LUT exceeds the number of unique entries, then the indexes of the table cannot be relied\n",
    "#upon to provide us with the correspondance to the relabeled atlas.  If this is the case, try and implement a workaround.\n",
    "if len(LUT)>len(np.unique(relabeledAtlasData)):\n",
    "    #infer which column contains the original identities\n",
    "    #presumably, this would be the LUT column with the largest number of matching labels with the original atlas.\n",
    "    matchingLabelsCount=[len(list(set(LUT[iColumns]).intersection(set(np.unique(atlasImg.get_fdata()).astype(int))))) for iColumns in LUT.columns.to_list()]\n",
    "    #there's an edge case here relabeled atlas == the original atlas AND the provided LUT was larger (what would the extra entries be?)\n",
    "    #worry about that later\n",
    "    columnBestGuess=LUT.columns.to_list()[matchingLabelsCount.index(np.max(matchingLabelsCount))]\n",
    "    #now that we have the guess, get the corresponding row entries, and reset the index.\n",
    "    #This should make the index match the renumbered label values.\n",
    "    LUTinterface=LUT[LUT[columnBestGuess].isin(np.unique(atlasImg.get_fdata()).astype(int)).values].reset_index(drop=True)\n",
    "    \n",
    "#proceed with working with the LUT.  Here we add the columns for selecting labels for segmentation / streamline extraction.\n",
    "if not(\"region1\" in LUTinterface.columns):\n",
    "    LUTinterface.insert(0, \"region1\", np.zeros([ len(LUTinterface),1],dtype=int), True)\n",
    "if not(\"region2\" in LUTinterface.columns):\n",
    "    LUTinterface.insert(1, \"region2\", np.zeros([ len(LUTinterface),1],dtype=int), True)\n",
    "\n",
    "#in order to provide some intuitons about where to look, add a column indicating the number of endpoints in that label.\n",
    "#this could probably just be an interative sum across row operation for the connectivty matrix.\n",
    "connectionLocations=[]\n",
    "#create a list of lists of all if the keys featuring this index\n",
    "for iIndexes in LUT.index.to_list():\n",
    "    connectionLocations.append( [iIndexes in sublist for sublist in list(grouping.keys())])\n",
    "    \n",
    "#get the dictionary keys in a list\n",
    "keyTargets=list(grouping.keys())\n",
    "#create a blank output vector\n",
    "streamCounts=np.zeros(len(LUTinterface),dtype=int)\n",
    "#iterate across all labels\n",
    "for iLabels in LUTinterface.index.to_list():\n",
    "    #find the dictionary keys which feature this connection\n",
    "    currentKeylocations=[i for i, x in enumerate(connectionLocations[iLabels]) if x]\n",
    "    #create a zero holder for a streamline accumulator/counter\n",
    "    currentStreamTotal=0\n",
    "    #iterate across the found connections for this key\n",
    "    for iCurrentConnections in currentKeylocations:\n",
    "        #add the number of streamlines to the streamline total\n",
    "        currentStreamTotal=currentStreamTotal+len(grouping[keyTargets[iCurrentConnections]])\n",
    "    #set the value\n",
    "    streamCounts[iLabels]=currentStreamTotal\n",
    "if not(\"endpointCount\" in LUTinterface.columns):\n",
    "    LUTinterface.insert(2, \"endpointCount\",streamCounts, True) \n",
    "    \n",
    "seg_entryTable_widget=qgrid.show_grid(LUTinterface,show_toolbar=True)\n",
    "seg_entryTable_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397797f",
   "metadata": {},
   "source": [
    "### Visualizing the selected streamlines\n",
    "\n",
    "To now perform the segmentation (after having made the above selection) run the next cell.  The streamlines displayed are those that have one endpoint in one the labels with 1 in the \"region1\" column and one endpoint in one the labels with 1 in the \"region2\" column.\n",
    "\n",
    "**Remember**: the visualization starts fairly far out--be sure to zoom in.  Press alt to allow for panning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f490c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that will be used to select streamlines from a larger tractogram\n",
    "def extractSubTractogram(sourceTractogram,indexes):\n",
    "    #import relevant package\n",
    "    import nibabel as nib\n",
    "    #extrect the desired streamlines into a new streamline object\n",
    "    streamlines = sourceTractogram.streamlines[indexes]\n",
    "    #establish tractogram object\n",
    "    out_tractogram = nib.streamlines.tractogram.Tractogram(streamlines)\n",
    "    return out_tractogram\n",
    "\n",
    "def plotParcellationConnectionWidget(tractogramToPlot):\n",
    "    #import widget\n",
    "    from niwidgets import StreamlineWidget\n",
    "    #set widget object\n",
    "    tractogramToPlot\n",
    "    sw = StreamlineWidget(streamlines=tractogramToPlot.streamlines)\n",
    "    #set plotting characteristics\n",
    "    style = {'axes': {'color': 'red',\n",
    "                'label': {'color': 'white'},\n",
    "                'ticklabel': {'color': 'white'},\n",
    "                'visible': False},\n",
    "                'background-color': 'black',\n",
    "                'box': {'visible': False},\n",
    "                'camera_fov':1}\n",
    "        \n",
    "    #plot it\n",
    "    #set a viable threshold for how many streamlines to default to plotting\n",
    "    #likely dependant on available resources and such\n",
    "    streamThresh=25000\n",
    "    if len(tractogramToPlot.streamlines)<=streamThresh:\n",
    "        defaultPercentile=0\n",
    "        print('Plotting tractogram for all ' + str(len(tractogramToPlot.streamlines)) + ' streamlines.') \n",
    "    else:\n",
    "        defaultPercentile=1-(len(tractogramToPlot.streamlines)/streamThresh)\n",
    "        print('Plotting tractogram for ' + str(((1-defaultPercentile)*streamThresh)) +' of ' + str(len(streamsObjIN.streamlines)) + ' streamlines.')\n",
    "      \n",
    "    sw.plot(display_fraction=1, width=1000, height=1000, style=style, percentile=defaultPercentile)\n",
    "segTable=LUTinterface\n",
    "#segTable=seg_entryTable_widget.get_changed_df()\n",
    "#check to make sure regions have actually be selected\n",
    "if sum(segTable['region1'].values)>0 and sum(segTable['region2'].values)>0:\n",
    "    #find the indexes for all of the labels that have been selected\n",
    "    region1Indexes=segTable[segTable['region1']==1].index.to_list()\n",
    "    region2Indexes=segTable[segTable['region2']==1].index.to_list()\n",
    "    import itertools\n",
    "    #find all of the combinations of the selected labels\n",
    "    permutationsLabels = list(itertools.product(region1Indexes, region2Indexes))\n",
    "    #create a flipped version of that (because we don't care about the orientation of the streamlines)\n",
    "    flippedLabels= [x[::-1] for x in permutationsLabels]\n",
    "    #combine those lists\n",
    "    combinedLabels=permutationsLabels+flippedLabels\n",
    "    #find the intersection of those combinations and the keys from the dipy tractome segmentation\n",
    "    validKeys=list(set(grouping.keys()).intersection(set(combinedLabels)))\n",
    "    #find the streamlines these connections correspond to\n",
    "    validStreamList=[grouping[iConnections] for iConnections in validKeys]\n",
    "    #convert that list of lists into a single list\n",
    "    validStreamlines=list(itertools.chain.from_iterable(validStreamList))\n",
    "    streamsToPlot=extractSubTractogram(streamsObjIN,validStreamlines)\n",
    "    display(plotParcellationConnectionWidget(streamsToPlot))\n",
    "else:\n",
    "    print('either region1 or region2 lacks selected labels.  Return to previous selection cell and select labels for both regions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6328fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load selected t1 image\n",
    "import nibabel as nib\n",
    "import os\n",
    "#load the T1\n",
    "T1ToLoad=(os.path.join(T1path.selected_path,T1path.selected_filename))\n",
    "t1img = nib.load(T1ToLoad)\n",
    "\n",
    "#use dipy to create the density mask\n",
    "from dipy.tracking import utils\n",
    "densityMap=utils.density_map(streamsToPlot.streamlines, t1img.affine, t1img.shape)\n",
    "densityNifti=nib.nifti1.Nifti1Image(densityMap,t1img.affine, t1img.header)\n",
    "\n",
    "from nilearn import plotting\n",
    "plotting.view_img(stat_map_img=densityNifti, bg_img=t1img, cut_coords=None,colorbar=True,vmin=0,vmax=np.max(densityNifti.get_fdata()),cmap='viridis', symmetric_cmap=False).resize(900,400)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
